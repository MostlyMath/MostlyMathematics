---
title: "Understanding Positive Definite Kernels"
date: "2025-09-18"
categories: [Analysis]
---

### Introduction

In functional analysis and related areas, we often encounter functions that speak of the relationships between points in a space (a metric or a distance function for instance). A kernel is such a function, taking two inputs and returning a real or a complex number, which can be interpreted as a measure of similarity or interaction.

Amongst these kernels, a special class called positive definite kernels play a central role as they are characterized by an intrinsic property that guarantees the existence of an associated Hilbert space of functions (a reproducing kernel Hilbert space, which we shall look into in another post).

Positive definite kernels are not just abstract objects, they also provide the foundation for constructing function spaces, understanding linear operators, and formulating problems in approximation theory and analysis. In this post, we will define positive definite kernels, explore some properties, and look into some examples.

### Positive Definite Kernels

Let us look at positive definite kernels in the real-valued case first.

> Let $\mathcal{X}$ be a set. $k: \mathcal{X} \times \mathcal{X} \to \mathbb{R}$ is a **positive definite kernel** if $k(x,y) = k(y,x)$ and for every $x_1, \dots, x_n \in \mathcal{X}$ and $c_1, \dots, c_n \in \mathbb{R}$ we have that $$\sum_{i,j=1}^{n} c_i c_j k(x_i, x_j) \ge 0,$$ i.e. the symmetric matrix: 

> $(k(x_i, x_j))_{i,j=1}^{n} = \begin{pmatrix}
k(x_1, x_1) & \cdots & k(x_1, x_n) \\
\vdots & \ddots & \vdots \\
k(x_n, x_1) & \cdots & k(x_n, x_n)
\end{pmatrix}$
is positive semidefinite.

Note that the symmetric matrix $(k(x_i, x_j))_{i,j=1}^{n}$ is often called a **Gram matrix**.

In the complex-valued case, the Hermitian property $k(y,x) = \overline{k(x,y)}$ is derived from the positive-definiteness itself.

> Let $\mathcal{X}$ be a set. 
$k : \mathcal{X} \times \mathcal{X} \to \mathbb{C}$ is a **positive definite kernel**
if for every $x_1, \dots, x_n \in \mathcal{X}$ and $c_1, \dots, c_n \in \mathbb{C}$, we have that $$\sum_{i,j=1}^{n} c_i \overline{c_j} k(x_i, x_j) \ge 0.$$

Before looking into some examples of positive definite kernels, we will look into some properties of the same and try to construct new positive definite kernels from the existing ones.

> **Proposition 1:** Assume $k : \mathcal{X} \times \mathcal{X} \to \mathbb{C}$ is positive definite. Then, for any $x, y \in \mathcal{X}$,  
  > 1. $k(x,x) \geq 0$.  
  > 2. $\lvert k(x,y) \rvert^2 \leq k(x,x) k(y,y)$.

The first statement is obvious from the definition (take $n=1, c_1 = 1, x_1 = x$). For (2) since a hermitian matrix is positive semidefinite iff all its eigenvalues are non-negative (Check!) and hence the determinant must be non-negative which gives us this inequality.

> **Proposition 2:** If $k_i : \mathcal{X} \times \mathcal{X} \to \mathbb{C} \ (i=1,2,\ldots)$ are positive definite kernels, then the following are also positive definite kernels.   
  > 1. $ak_1 + bk_2 \quad (a,b \geq 0)$ (positive combination)  
  > 2. $k_1 k_2$ (product)  
  > 3. $\lim_{i \to \infty} k_i(x,y),$ assuming the limit exists.  



> **Proposition 3:** Let $V$ be a vector space with an inner product $\langle \cdot , \cdot \rangle$. If we have a map $\Phi : \mathcal{X} \to V; x \mapsto \Phi(x)$, a positive definite kernel on $\mathcal{X}$ is defined by $$k(x,y) = \langle \Phi(x), \Phi(y) \rangle.$$

> **Proposition 4:** Let $k : \mathcal{X} \times \mathcal{X} \to \mathbb{C}$ be a positive definite kernel and $f : \mathcal{X} \to \mathbb{C}$ be an arbitrary function. Then, $\tilde{k}(x,y) = f(x) \, k(x,y) \, \overline{f(y)}$ is positive definite. In particular, $f(x)\overline{f(y)}$ is a positive definite kernel.

### Examples

- Linear Kernel: $$k_0(x,y) = x^{T}y$$ 
- Exponential Kernel: $$k_E(x,y) = exp(\beta x^{T}y) \quad \text{where} \quad \beta > 0$$  
- Gaussian Radial Basis Function Kernel:  $$
k_G(x,y) = \exp\!\left(-\frac{1}{2\sigma^2}\|x-y\|^2\right) \quad \text{where} \quad (\sigma > 0)$$






