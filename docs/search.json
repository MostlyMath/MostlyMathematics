[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Positive Definite Kernels",
    "section": "",
    "text": "Introduction\nThis post is Part I of the series on reproducing kernel Hilbert spaces (RKHS). In functional analysis and related areas, we often encounter functions that speak of the relationships between points in a space (a metric or a distance function for instance). A kernel is such a function, taking two inputs and returning a real or a complex number, which can be interpreted as a measure of similarity or interaction.\nAmongst these kernels, a special class called positive definite kernels play a central role as they are characterized by an intrinsic property that guarantees the existence of an associated Hilbert space of functions (a reproducing kernel Hilbert space which we will look into in the next post).\nPositive definite kernels are not just abstract objects, they also provide the foundation for constructing function spaces, understanding linear operators, and formulating problems in approximation theory and analysis. In this post, we will define positive definite kernels, explore some properties, and look into some examples.\n\n\nPositive Definite Kernels\nLet us look at positive definite kernels in the real-valued case first.\n\nLet \\(\\mathcal{X}\\) be a set. \\(k: \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{R}\\) is a positive definite kernel if \\(k(x,y) = k(y,x)\\) and for every \\(x_1, \\dots, x_n \\in \\mathcal{X}\\) and \\(c_1, \\dots, c_n \\in \\mathbb{R}\\) we have that \\[\\sum_{i,j=1}^{n} c_i c_j k(x_i, x_j) \\ge 0,\\] i.e. the symmetric matrix:\n\n\n\\((k(x_i, x_j))_{i,j=1}^{n} = \\begin{pmatrix}\nk(x_1, x_1) & \\cdots & k(x_1, x_n) \\\\\n\\vdots & \\ddots & \\vdots \\\\\nk(x_n, x_1) & \\cdots & k(x_n, x_n)\n\\end{pmatrix}\\) is positive semidefinite.\n\nSo basically, positive definite kernels are those functions whose weighted combinations over any finite set of points are always non-negative. Note that the symmetric matrix \\((k(x_i, x_j))_{i,j=1}^{n}\\) is often called a Gram matrix.\nIn the complex-valued case, the Hermitian property \\(k(y,x) = \\overline{k(x,y)}\\) is derived from the positive-definiteness itself.\n\nLet \\(\\mathcal{X}\\) be a set. \\(k : \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{C}\\) is a positive definite kernel if for every \\(x_1, \\dots, x_n \\in \\mathcal{X}\\) and \\(c_1, \\dots, c_n \\in \\mathbb{C}\\), we have that \\[\\sum_{i,j=1}^{n} c_i \\overline{c_j} k(x_i, x_j) \\ge 0.\\]\n\nBefore looking into some examples of positive definite kernels, we will look into some properties of the same and try to construct new positive definite kernels from the existing ones.\n\nProposition 1: Assume \\(k : \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{C}\\) is positive definite. Then, for any \\(x, y \\in \\mathcal{X}\\),\n1. \\(k(x,x) \\geq 0\\).\n2. \\(\\lvert k(x,y) \\rvert^2 \\leq k(x,x) k(y,y)\\).\n\n\nProof: (1) is obvious from the definition (take \\(n=1, c_1 = 1, x_1 = x\\)). For (2) since a hermitian matrix is positive semidefinite iff all its eigenvalues are non-negative (Check!), the determinant must be non-negative which gives us this inequality.\n\nFrom Proposition 1 we get the hints of structure hidden in positive definite kernels. The non-negativity of \\(k(x,x)\\) and the Cauchy-Schwarz-type inequality suggest that these kernels behave a lot like inner products even if we haven’t formally embedded the points in a Hilbert space yet.\nOne nice property of positive definite kernels is that adding kernels, multiplying them, or taking limits produces new positive definite kernels. This lets us construct more complex kernels from simple ones.\n\nProposition 2: If \\(k_i : \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{C} \\ (i=1,2,\\ldots)\\) are positive definite kernels, then the following are also positive definite kernels.\n1. \\(ak_1 + bk_2 \\quad (a,b \\geq 0)\\) (positive combination)\n2. \\(k_1 k_2\\) (product)\n3. \\(\\lim_{i \\to \\infty} k_i(x,y),\\) assuming the limit exists.\n\n\nProof: (1) and (3) are easy to see and for (2), it is enough to show that if two Hermitian matrices \\(A\\) and \\(B\\) are positive semidefinite, so is their component wise product (the Hadamard product). This can be done by taking the eigendecomposition of \\(A\\) and then checking for the positve semidefiniteness of the Hadamard product.\n\nSo far we looked at kernels abstractly. Proposition 3 shows how positive definite kernels naturally arise from inner products in some vector space. This is the first step towards seeing kernels encoding hidden geometries.\n\nProposition 3: Let \\(V\\) be a vector space with an inner product \\(\\langle \\cdot , \\cdot \\rangle\\). If we have a map \\(\\Phi : \\mathcal{X} \\to V; x \\mapsto \\Phi(x)\\), a positive definite kernel on \\(\\mathcal{X}\\) is defined by \\[k(x,y) = \\langle \\Phi(x), \\Phi(y) \\rangle.\\]\n\n\nProof: Let \\(x_1, \\ldots, x_n\\) in \\(\\mathcal{X}\\) and \\(c_1, \\ldots, c_n \\in \\mathbb{C}\\). \\[\n\\begin{align*}\n\\sum_{i,j=1}^n c_i \\overline{c_j} k(x_i, x_j)\n&= \\sum_{i,j=1}^n c_i \\overline{c_j} \\langle \\Phi(x_i), \\Phi(x_j) \\rangle = \\left\\langle \\sum_{i=1}^n c_i \\Phi(x_i), \\sum_{j=1}^n c_j \\Phi(x_j) \\right\\rangle = \\left\\| \\sum_{i=1}^n c_i \\Phi(x_i) \\right\\|^2 \\geq 0.\n\\end{align*}\n\\]\n\nProposition 4 shows how kernels can be “reweighted” by arbitrary functions to produce new kernels.\n\nProposition 4: Let \\(k : \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{C}\\) be a positive definite kernel and \\(f : \\mathcal{X} \\to \\mathbb{C}\\) be an arbitrary function. Then, \\(\\tilde{k}(x,y) = f(x) \\, k(x,y) \\, \\overline{f(y)}\\) is positive definite. In particular, \\(f(x)\\overline{f(y)}\\) is a positive definite kernel.\n\n\nProof: Consider any \\(n \\in \\mathbb{N}\\), \\(x_1, \\ldots, x_n \\in \\mathcal{X}\\), and \\(c_1, \\ldots, c_n \\in \\mathbb{C}\\) \\[\n\\sum_{i,j=1}^n c_i \\overline{c_j} \\tilde{k}(x_i, x_j)\n= \\sum_{i,j=1}^n c_i \\overline{c_j} f(x_i) k(x_i, x_j) \\overline{f(x_j)}  \n\\] Let \\(d_i = c_i f(x_i)\\). Then since \\(k\\) is positive definite we have \\[\n\\sum_{i,j=1}^n d_i \\overline{d_j} k(x_i, x_j) \\geq 0\n\\]\n\nNow that we know how to construct positive definite kernels, let us see some concrete examples.\n\n\nExamples\n\nLinear Kernel: \\[k_0(x,y) = x^{T}y\\] This directly follows from Proposition 3\nExponential Kernel: \\[k_E(x,y) = exp(\\beta x^{T}y) \\quad \\text{where} \\quad \\beta &gt; 0\\]\nThis follows from the previous example and applying Proposition 2 after taking: \\[\n\\exp(\\beta x^T y) = 1 + \\beta x^T y + \\frac{\\beta^2}{2!}(x^T y)^2 + \\frac{\\beta^3}{3!}(x^T y)^3 + \\cdots\n\\]\nGaussian Radial Basis Function Kernel: \\[\nk_G(x,y) = \\exp\\!\\left(-\\frac{1}{2\\sigma^2}\\|x-y\\|^2\\right) \\quad \\text{where} \\quad (\\sigma &gt; 0)\\] This follows from Proposition 4 after taking: \\[\n\\exp\\left(-\\frac{1}{2\\sigma^2} \\|x - y\\|^2 \\right) = \\exp\\left(-\\frac{\\|x\\|^2}{2\\sigma^2}\\right) \\exp\\left(\\frac{x^T y}{\\sigma^2}\\right) \\exp\\left(-\\frac{\\|y\\|^2}{2\\sigma^2}\\right)\n\\]\n\nOn a concluding note, we saw the definition of a positive definite kernel and the ways to construct more such kernels which led to some examples. Our goal is to understand how positive definite kernels behave like inner products once you embed points into the appropriate Hilbert space which we will look into in the next post.\n\n\n\n\n\n\n\n\nReferences\n\nAronszajn, Nachman. 1950. “Theory of Reproducing Kernels.” Transactions of the American Mathematical Society 68 (3): 337–404. https://doi.org/10.1090/S0002-9947-1950-0037978-4.\n\n\nBerlinet, Alain, and Christine Thomas-Agnan. 2004. Reproducing Kernel Hilbert Spaces in Probability and Statistics. Springer Science & Business Media.\n\n\nFukumizu, Kenji. 2008. “Elements of Positive Definite Kernel and Reproducing Kernel Hilbert Space: Statistical Inference with Reproducing Kernel Hilbert Space.” Institute of Statistical Mathematics, ROIS; Department of Statistical Science, Graduate University for Advanced Studies; https://www.ism.ac.jp/~fukumizu/H20_kernel/Kernel_2_elements.pdf.",
    "crumbs": [
      "Home",
      "Posts",
      "Positive Definite Kernels"
    ]
  },
  {
    "objectID": "posts/my-first-post/index.html",
    "href": "posts/my-first-post/index.html",
    "title": "Poincaré Recurrence",
    "section": "",
    "text": "When we talk of dynamical systems, the basic idea is that we pick a space \\(X\\), choose a rule \\(T: X \\to X\\), and then we keep applying that rule over and over again to a point \\(x \\in X\\).\nSo if we start with \\(x\\), then apply \\(T\\), we obtain \\(T(x)\\). Applying it again, we obtain \\(T^2(x)\\), then \\(T^3(x)\\), and so on. The sequence\n\\[\nx, \\; T(x), \\; T^2(x), \\; T^3(x), \\dots\n\\]\nis called the orbit of \\(x\\) under \\(T\\) which is the most natural object to study since the orbit tells us the future path of the point.\nNow a good question to ask would be: What happens to these orbits in the longer run? One can wonder if they keep running away to new territories forever? Or if they loop back and revisit old places? Or if they somehow spread out evenly across space?\nConsider the following simple example:\n\nIf \\(X\\) is a circle and \\(T\\) is rotation by \\(90^\\circ\\), then orbits are perfectly periodic. After four steps, we are back at where we started.\n\nIf the angle is irrational, then the orbit never lands exactly where it started. But it does keep wandering around the circle in such a way that eventually it perhaps comes arbitrarily close to the starting point.\n\nSo a nice thing to wonder would be if coming back close to where we started is a general phenomenon or not.\nTo even begin answering this, we need some extra structure. Just having a set \\(X\\) and a map \\(T\\) is too vague. What we want is a way to say something like: “most points behave this way.” And the right tool for that is measure theory.\nIf we give our space a measure (so we can talk about sizes of sets, probabilities, and so on), and if our transformation \\(T\\) respects that measure, we might be able to answer our question. And hence we consider the setting of a measure-preserving system.\nAnd in this setting we have a deep and beautiful result: the Poincaré Recurrence Theorem, which tells us something quite striking about orbits. But before we get there, let’s first understand what measure-preserving systems actually are.",
    "crumbs": [
      "Home",
      "Posts",
      "Poincaré Recurrence"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mostly Mathematics",
    "section": "",
    "text": "Mostly Mathematics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReproducing Kernel Hilbert Spaces - An Introduction\n\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nSep 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPositive Definite Kernels\n\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nSep 15, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nThe Birkhoff’s Ergodic Theorem\n\n\n\nAnalysis\n\nDynamics\n\n\n\n\n\n\n\n\n\nSep 10, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nPoincaré Recurrence\n\n\n\nAnalysis\n\nDynamics\n\n\n\n\n\n\n\n\n\nSep 5, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "\nAbout\n",
    "section": "",
    "text": "About\n\n\nHey everyone! This is Aparna Bade, a mathematics graduate from IISER Thiruvananthapuram. I am trying to get better at math by communicating and sharing it. I want to try and post short intuitive snippets to elaboarate proofs of fun theorems. Feel free to question, criticize, and improvise this page.",
    "crumbs": [
      "Home",
      "About"
    ]
  },
  {
    "objectID": "posts/fourth post/index.html",
    "href": "posts/fourth post/index.html",
    "title": "Reproducing Kernel Hilbert Spaces - An Introduction",
    "section": "",
    "text": "This post is Part II of the series on Reproducing Kernel Hilbert Spaces (RKHS). We have so far looked at Positive Definite Kernels: special functions \\(k(x,y)\\) that produce Gram matrices that are positive semidefinite for any finite set of points. At first glance, this definition may feel a little abstract making us wonder why we should even care about kernels satisfying such an inequality.\nOne reason is that positive definite kernels secretly encode a hidden geometry: each kernel corresponds to a Hilbert space of functions, where the kernel itself acts as a sort of “building block.” This Hilbert space is what we call a Reproducing Kernel Hilbert Space (RKHS).\nWhat makes an RKHS so interesting is the reproducing property. In an RKHS \\(\\mathcal{H}\\), evaluating a function at a point \\(x\\) can be done by taking an inner product with a special function \\(k_x\\) corresponding to that point: \\[ f(x) = {\\langle f, k_x \\rangle}_{\\mathcal{H}} \\]\nWhy is it useful? Firstly it simply guarantees that point evaluation is always a nice, continuous operation (unlike in some spaces such as \\({\\mathcal{L}}^2\\), where evaluation doesn’t even make sense). Secondly it lays the mathematical foundation for many mathematical applications including machine learning algorithms (like kernel methods and Gaussian processes), signal processing, approximation theory, and even parts of harmonic analysis rely substantially on RKHS.\nIn this post, we will understand the relation between positive definite kernels and reproducing kernel Hilbert spaces. We will see that every RKHS comes with a unique reproducing kernel which is positive definite, and that every positive definite kernel gives rise to a corresponding RKHS.",
    "crumbs": [
      "Home",
      "Posts",
      "Reproducing Kernel Hilbert Spaces - An Introduction"
    ]
  },
  {
    "objectID": "posts/fourth post/index.html#reproducing-kernel-hilbert-spaces-rkhs",
    "href": "posts/fourth post/index.html#reproducing-kernel-hilbert-spaces-rkhs",
    "title": "Reproducing Kernel Hilbert Spaces - An Introduction",
    "section": "Reproducing Kernel Hilbert Spaces (RKHS)",
    "text": "Reproducing Kernel Hilbert Spaces (RKHS)\n\nLet \\(\\mathcal{X}\\) be a set. A reproducing kernel Hilbert space (RKHS) over \\(\\mathcal{X}\\) is a Hilbert space \\(\\mathcal{H}\\) consisting of functions on \\(\\mathcal{X}\\) such that for each \\(x \\in \\mathcal{X}\\) there is a function \\(k_x \\in \\mathcal{H}\\) with the reproducing property \\[\n\\langle f, k_x \\rangle_\\mathcal{H} = f(x) \\qquad ;\\forall f \\in \\mathcal{H} \\qquad .\n\\] Considering \\(k(\\cdot, x) = k_x(\\cdot)\\). The function \\(k\\) is called a reproducing kernel of \\(\\mathcal{H}\\).\n\nSimply speaking, the evaluation of any function from \\(\\mathcal{H}\\) at each \\(x \\in \\mathcal{X}\\) is the same as taking the inner product of \\(f\\) with a corresponding \\(k_x\\) in \\(\\mathcal{H}\\). We will prove that the above reproducing kernel is in fact a positive definite kernel on \\(\\mathcal{X}\\). Firstly, applying the reproducing property above to the function \\(k(\\cdot,x_j)\\) (which is in \\(\\mathcal{H}\\)) at the point \\(x_i\\) we get: \\(k(x_i,x_j) = k_{x_j}(x_i) = {\\langle k(\\cdot,x_j), k(\\cdot,x_i)\\rangle}_{\\mathcal{H}}\\). We will use this equality in further proofs.\n\nProposition 1: A reproducing kernel of a RKHS is a positive definite kernel on \\(X\\).\n\n\nProof: Using the above equality we obtain\\[\n\\sum_{i,j=1}^n c_i \\overline{c_j} k(x_i, x_j)\n= \\sum_{i,j=1}^n c_i \\overline{c_j} \\langle k(\\cdot, x_j), k(\\cdot, x_i) \\rangle\n= \\left\\langle \\sum_{i=1}^n c_i k(\\cdot, x_i), \\sum_{j=1}^n c_j k(\\cdot, x_j) \\right\\rangle\n\\geq 0\n\\]\n\nNote that the reproducing kernel on a Hilbert space is unique if it exists. Suppose \\(k\\) and \\(\\tilde{k}\\) are reproducing kernels. Then we have \\(\\widetilde{k}(x, y) = \\langle \\widetilde{k}(\\cdot, y), k(\\cdot, x) \\rangle = \\langle k(\\cdot, x), \\widetilde{k}(\\cdot, y) \\rangle = \\overline{k(y, x)} = k(x, y)\\).\nAlso note that \\(\\|k(\\cdot, x)\\| = \\sqrt{k(x, x)}\\) since \\(\\|k(\\cdot, x)\\|^2 = \\langle k(\\cdot, x), k(\\cdot, x) \\rangle = k(x, x)\\).\nAt this point we might wonder why we care about this reproducing property and what it has to do with evaluation at a point. The key is that evaluation should be a nice operation. Like we noted before, in some Hilbert spaces of functions (like \\({\\mathcal{L}}^2\\)), evaluation doesn’t even make sense as two different-looking functions might represent the same element of the space making \\(f(x)\\) ambiguous.\nTo avoid this, we require that the evaluation map \\(e_x(f) = f(x)\\) to be a continuous linear functional for every point \\(x\\). Once this condition holds, the Riesz representation theorem guarantees the existence of the kernel elements \\(k_x\\) and the reproducing property follows naturally. In fact, the continuity of evaluation functions characterizes RKHS.\n\nProposition 2: Let \\(\\mathcal{H}\\) be a Hilbert space consisting of functions on a set \\(\\mathcal{X}\\). Then \\(\\mathcal{H}\\) is a RKHS iff the evaluation map \\(e_x : \\mathcal{H} \\rightarrow \\mathbb{F}, e_x(f) = f(x)\\), is a continuous linear functional for each \\(x \\in \\mathcal{X}\\).\n\n\nProof: Assume \\(\\mathcal{H}\\) is a RKHS. We obtain the boundedness of \\(e_x\\) from \\[|e_x(f)| = |\\langle f, k_x \\rangle| \\leq \\|k_x\\| \\|f\\|.\\] Conversely, let’s assume that the evaluation map is continuous. By Riesz representation theorem, there exists a \\(k_x \\in \\mathcal{H}\\) such that \\[\\langle f, k_x \\rangle = e_x(f) = f(x).\\]\n\nSo far, we’ve seen the following two things:\n\nEvery RKHS has a reproducing kernel which turns out to be positive definite.\nEvaluation functionals being continuous is exactly what makes this setup work.\n\nThe natural question now is: given just a positive definite kernel, can we always build the “corresponding” Hilbert space in some sense.\nTurns out, every positive definite kernel corresponds to a unique RKHS. In other words, kernels are not just abstract inequalities, they actually encode entire Hilbert spaces of functions. Theorem 3 makes this precise.\n\nTheorem 3: Let \\(k : \\mathcal{X} \\times \\mathcal{X} \\to \\mathbb{C}\\) (or \\(\\mathbb{R}\\)) be a positive definite kernel on a set \\(\\mathcal{X}\\). Then, there uniquely exists a RKHS \\(\\mathcal{H}_k\\) consisting of functions on \\(\\mathcal{X}\\) such that\n1. \\(k(\\cdot, x) \\in \\mathcal{H}_k\\) for every \\(x \\in \\mathcal{X}\\),\n2. Span \\(\\{k(\\cdot, x) \\mid x \\in \\mathcal{X}\\}\\) is dense in \\(\\mathcal{H}_k\\),\n3. \\(k\\) is a reproducing kernel on \\(\\mathcal{H}_k\\), i.e. \\(\\langle f, k(\\cdot, x) \\rangle_{\\mathcal{H}_k} = f(x),\\) for all x and \\(f \\in \\mathcal{H}_k.\\)\n\nTheorem 3 is the big result we were aiming for: every positive definite kernel actually generates a unique RKHS. This shows that kernels are not just abstract objects and that they encode entire function spaces with nice geometric properties. In the next post, we will probably dive into the proof and see exactly how this Hilbert space is constructed from the kernel. We will also look at some concrete examples of RKHS and explicitly write their reproducing kernels.",
    "crumbs": [
      "Home",
      "Posts",
      "Reproducing Kernel Hilbert Spaces - An Introduction"
    ]
  }
]